{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import extractor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading complete\n"
     ]
    }
   ],
   "source": [
    "# First We extract featueres from raw data and select an user for training our One Class SVM Model\n",
    "\n",
    "print(\"Loading Data\")\n",
    "\n",
    "# User1\n",
    "X_user1= extractor.features(34,\"Data-1/\")\n",
    "#print(X_user1.shape)\n",
    "X_user1 = preprocessing.scale(X_user1,axis=0)\n",
    "\n",
    "# User2\n",
    "X_user2= extractor.features(13,\"Data-2/\")\n",
    "#print(X_user2.shape)\n",
    "X_user2 = preprocessing.scale(X_user2,axis=0)\n",
    "\n",
    "\n",
    "# User3\n",
    "X_user3= extractor.features(28,\"Data-3/\")\n",
    "#print(X_user3.shape)\n",
    "X_user3 = preprocessing.scale(X_user3,axis=0)\n",
    "\n",
    "\n",
    "# User4\n",
    "X_user4= extractor.features(34,\"Data-4/\")\n",
    "#print(X_user4.shape)\n",
    "X_user4 = preprocessing.scale(X_user4,axis=0)\n",
    "\n",
    "\n",
    "# User5\n",
    "X_user5= extractor.features(20,\"Data-5/\")\n",
    "#print(X_user5.shape)\n",
    "X_user5 = preprocessing.scale(X_user5,axis=0)\n",
    "# User6\n",
    "X_user6= extractor.features(23,\"Data-6/\")\n",
    "#print(X_user6.shape)\n",
    "X_user6 = preprocessing.scale(X_user6,axis=0)\n",
    "# User7\n",
    "X_user7= extractor.features(28,\"Data-7/\")\n",
    "#print(X_user7.shape)\n",
    "X_user7 = preprocessing.scale(X_user7,axis=0)\n",
    "# User8\n",
    "X_user8= extractor.features(22,\"Data-8/\")\n",
    "X_user8 = preprocessing.scale(X_user8,axis=0)#print(X_user8.shape)\n",
    "\n",
    "\n",
    "# User9\n",
    "X_user9= extractor.features(9,\"Data-9/\")\n",
    "#print(X_user9.shape)\n",
    "X_user9 = preprocessing.scale(X_user9,axis=0)\n",
    "\n",
    "# User10\n",
    "X_user10= extractor.features(20,\"Data-10/\")\n",
    "#print(X_user10.shape)\n",
    "X_user10 = preprocessing.scale(X_user10,axis=0)\n",
    "\n",
    "# User11\n",
    "X_user11= extractor.features(35,\"Data-11/\")\n",
    "#print(X_user11.shape)\n",
    "X_user11 = preprocessing.scale(X_user11,axis=0)\n",
    "\n",
    "# User12\n",
    "X_user12= extractor.features(10,\"Data-12/\")\n",
    "#print(X_user12.shape)\n",
    "X_user12 = preprocessing.scale(X_user12,axis=0)\n",
    "\n",
    "# User13\n",
    "X_user13= extractor.features(32,\"Data-13/\")\n",
    "#print(X_user13.shape)\n",
    "X_user13 = preprocessing.scale(X_user13,axis=0)\n",
    "\n",
    "# User14\n",
    "X_user14= extractor.features(44,\"Data-14/\")\n",
    "#print(X_user14.shape)\n",
    "X_user14 = preprocessing.scale(X_user14,axis=0)\n",
    "\n",
    "# User15\n",
    "X_user15= extractor.features(80,\"Data-15/\")\n",
    "#print(X_user15.shape)\n",
    "X_user15 = preprocessing.scale(X_user15,axis=0)\n",
    "\n",
    "print(\"Data Loading complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Data From user-14 to train our model\n",
      "Ranking of features: [(0.8488, 'v_min'), (0.0849, 'theta_max'), (0.0365, 'vdd_max'), (0.0239, 'vy_max'), (0.0035, 'vy_std'), (0.0007, 'vx_max'), (0.0002, 'pause_count'), (0.0001, 'vy_min'), (0.0001, 'vy_mean'), (0.0001, 'vx_min'), (0.0001, 'vx_mean'), (0.0001, 'vx_diff'), (0.0001, 'vdot_mean'), (0.0001, 'vdot_max'), (0.0001, 'vdot_diff'), (0.0001, 'vdd_mean'), (0.0001, 'v_mean'), (0.0001, 'critical_count'), (0.0, 'y_std'), (0.0, 'y_min'), (0.0, 'y_mean'), (0.0, 'y_max'), (0.0, 'y_diff'), (0.0, 'x_std'), (0.0, 'x_min'), (0.0, 'x_mean'), (0.0, 'x_max'), (0.0, 'x_diff'), (0.0, 'w_std'), (0.0, 'w_min'), (0.0, 'w_mean'), (0.0, 'w_max'), (0.0, 'w_diff'), (0.0, 'vy_diff'), (0.0, 'vx_std'), (0.0, 'vdot_std'), (0.0, 'vdot_min'), (0.0, 'vdd_std'), (0.0, 'vdd_min'), (0.0, 'vdd_diff'), (0.0, 'v_std'), (0.0, 'v_max'), (0.0, 'v_diff'), (0.0, 'total_pause_time'), (0.0, 'theta_std'), (0.0, 'theta_min'), (0.0, 'theta_mean'), (0.0, 'theta_diff'), (0.0, 't'), (0.0, 'pause_time_ratio'), (0.0, 'label'), (0.0, 'l'), (0.0, 'delta_c_std'), (0.0, 'delta_c_min'), (0.0, 'delta_c_mean'), (0.0, 'delta_c_max'), (0.0, 'delta_c_diff'), (0.0, 'click_time'), (0.0, 'c_std'), (0.0, 'c_min'), (0.0, 'c_mean'), (0.0, 'c_max'), (0.0, 'c_diff')]\n",
      "Selected Features: vy_max v_min vdd_max theta_max \n",
      "Index of selected features: [18, 22, 33, 38]\n",
      "Number of selected features: 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The obtained features are 63 Dimensional, first we use Random Forest Regressor to rank the features according to \n",
    "their relative importance and select the features upto a certain value of feature importance\n",
    "\"\"\"\n",
    "\n",
    "# Select the user from here for whom the system is to be designed.\n",
    "\n",
    "# We perform it twice. Once for user-14 and once for user-15\n",
    "\n",
    "print(\"Using Data From user-1 to train our model\")\n",
    "#print(\"Using Data From user-15 to train our model\")\n",
    "\n",
    "X_user = np.concatenate((X_user1,X_user2,X_user3,X_user4,X_user5,X_user6,X_user7,X_user8,X_user9,X_user10,\n",
    "                        X_user11,X_user12,X_user13,X_user14,X_user15),axis=0)\n",
    "Y = np.concatenate((1*np.ones(X_user1.shape[0]),-1*np.ones(X_user2.shape[0]),-1*np.ones(X_user3.shape[0]),\n",
    "                    -1*np.ones(X_user4.shape[0]),-1*np.ones(X_user5.shape[0]),-1*np.ones(X_user6.shape[0]),\n",
    "                   -1*np.ones(X_user7.shape[0]),-1*np.ones(X_user8.shape[0]),-1*np.ones(X_user9.shape[0])\n",
    "                   ,-1*np.ones(X_user10.shape[0]),-1*np.ones(X_user11.shape[0]),-1*np.ones(X_user12.shape[0]),\n",
    "                   -1*np.ones(X_user13.shape[0]),-1*np.ones(X_user14.shape[0]),-1*np.ones(X_user15.shape[0])),axis=0)\n",
    "\n",
    "\n",
    "labels = np.array(['x_mean', 'x_std', 'x_min', 'x_max', 'x_diff',\n",
    "                              'y_mean', 'y_std', 'y_min', 'y_max', 'y_diff',\n",
    "                              'vx_mean', 'vx_std', 'vx_min', 'vx_max', 'vx_diff',\n",
    "                              'vy_mean', 'vy_std', 'vy_min', 'vy_max', 'vy_diff',\n",
    "                              'v_mean', 'v_std', 'v_min', 'v_max', 'v_diff',\n",
    "                              'vdot_mean', 'vdot_std', 'vdot_min', 'vdot_max', 'vdot_diff',\n",
    "                              'vdd_mean', 'vdd_std', 'vdd_min', 'vdd_max', 'vdd_diff',\n",
    "                              'theta_mean', 'theta_std', 'theta_min', 'theta_max', 'theta_diff',\n",
    "                              'c_mean', 'c_std', 'c_min', 'c_max', 'c_diff',\n",
    "                              'delta_c_mean', 'delta_c_std', 'delta_c_min', 'delta_c_max', 'delta_c_diff',\n",
    "                              'w_mean', 'w_std', 'w_min', 'w_max', 'w_diff',\n",
    "                              't', 'l', 'critical_count', 'click_time', 'pause_count',\n",
    "                              'total_pause_time', 'pause_time_ratio', 'label'])\n",
    "#print(type(labels))\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_user, Y)\n",
    "list=[]\n",
    "print(\"Ranking of features:\"),\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), labels),reverse=True)\n",
    "print(\"Selected Features:\"),\n",
    "for i in range (X_user.shape[1]):\n",
    "    if (rf.feature_importances_[i]>=0.005):\n",
    "        list.append(i)\n",
    "        print(labels[i]),\n",
    "print(\"\")\n",
    "print(\"Index of selected features:\"),\n",
    "print(list)\n",
    "print(\"Number of selected features:\"),\n",
    "print(len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only relevant features given by the feature extraction algorithm for all the features\n",
    "X_user1 = X_user1[:,list]\n",
    "X_user2 = X_user2[:,list]\n",
    "X_user3 = X_user3[:,list]\n",
    "X_user4 = X_user4[:,list]\n",
    "X_user5 = X_user5[:,list]\n",
    "X_user6 = X_user6[:,list]\n",
    "X_user7 = X_user7[:,list]\n",
    "X_user8 = X_user8[:,list]\n",
    "X_user9 = X_user9[:,list]\n",
    "X_user10 = X_user10[:,list]\n",
    "X_user11 = X_user11[:,list]\n",
    "X_user12 = X_user12[:,list]\n",
    "X_user13 = X_user13[:,list]\n",
    "X_user14 = X_user14[:,list]\n",
    "X_user15 = X_user15[:,list]\n",
    "\n",
    "#print(X_user14.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose User\n",
    "Training_Data = X_user1\n",
    "np.random.shuffle(Training_Data)\n",
    "delta = int(Training_Data.shape[0]/5)\n",
    "Train_part1 = Training_Data[0:delta,:]\n",
    "Train_part2 = Training_Data[delta:2*delta,:]\n",
    "Train_part3 = Training_Data[2*delta:3*delta,:]\n",
    "Train_part4 = Training_Data[3*delta:4*delta,:]\n",
    "Train_part5 = Training_Data[4*delta:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Non Users\n",
    "X_other_users = np.concatenate((X_user1,X_user2,X_user3,X_user4,X_user5,X_user6,\n",
    "                              X_user7,X_user8,X_user9,X_user10,X_user11,X_user12,X_user13,X_user15),axis=0)\n",
    "Y_other_users = -1*np.ones(X_other_users.shape[0],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 78.1124497992\n",
      "Test accuracy: 41.4629479022\n",
      "Precision: 0.0310827007591\n",
      "Recall: 0.779559118236\n",
      "F1 Score: 0.0597817734747\n"
     ]
    }
   ],
   "source": [
    "# Fold 1 Cross validation\n",
    "Train_Data = np.concatenate((Train_part1,Train_part2,Train_part3,Train_part4),axis=0)\n",
    "Test_Data =  np.concatenate((Train_part5,X_other_users),axis=0)\n",
    "Test_Data_Label = np.concatenate((np.ones(Train_part5.shape[0],dtype=int),Y_other_users),axis=0)\n",
    "\n",
    "\n",
    "clf = svm.OneClassSVM(kernel='rbf', gamma=0.3, nu=0.22)\n",
    "clf.fit(Train_Data)\n",
    "\n",
    "\n",
    "# Accuracy on Training Data\n",
    "y_train= clf.predict(Train_Data)\n",
    "count=0\n",
    "for i in range(y_train.shape[0]):\n",
    "    if (y_train[i]==1):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_train.shape[0])\n",
    "print(\"Training accuracy:\"),\n",
    "print(float(count*100)/y_train.shape[0])\n",
    "\n",
    "\n",
    "# Accuracy on Test Data\n",
    "y_test= clf.predict(Test_Data)\n",
    "count=0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==Test_Data_Label[i]):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_test.shape[0])\n",
    "print(\"Test accuracy:\"),\n",
    "print(float(count*100)/y_test.shape[0])  \n",
    "\n",
    "tp=0\n",
    "tn=0\n",
    "fp=0\n",
    "fn=0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            tp=tp+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            fp=fp+1\n",
    "    if (y_test[i]==-1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            fn=fn+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            tn=tn+1\n",
    "            \n",
    "\n",
    "#print(tp,fp,tn,fn)     \n",
    "precision = float(tp)/float(tp+fp)\n",
    "recall = float(tp)/float(tp+fn)\n",
    "F1_score = (2* precision* recall)/(precision+recall)\n",
    "print(\"Precision:\"),\n",
    "print(precision)\n",
    "print(\"Recall:\"),\n",
    "print(recall)\n",
    "print(\"F1 Score:\"),\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 78.0230807827\n",
      "Test accuracy: 41.8763754665\n",
      "Precision: 0.0309642226857\n",
      "Recall: 0.774322968907\n",
      "F1 Score: 0.0595472251147\n"
     ]
    }
   ],
   "source": [
    "# Fold 2 Cross validation\n",
    "Train_Data = np.concatenate((Train_part1,Train_part2,Train_part3,Train_part5),axis=0)\n",
    "Test_Data = np.concatenate((Train_part4,X_other_users),axis=0)\n",
    "Test_Data_Label = np.concatenate((np.ones(Train_part4.shape[0],dtype=int),Y_other_users),axis=0)\n",
    "\n",
    "clf = svm.OneClassSVM(kernel='rbf', gamma=0.3, nu=0.22)\n",
    "clf.fit(Train_Data)\n",
    "\n",
    "\n",
    "# Accuracy on Training Data\n",
    "y_train= clf.predict(Train_Data)\n",
    "count=0\n",
    "for i in range(y_train.shape[0]):\n",
    "    if (y_train[i]==1):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_train.shape[0])\n",
    "print(\"Training accuracy:\"),\n",
    "print(float(count*100)/y_train.shape[0])\n",
    "\n",
    "\n",
    "# Accuracy on Test Data\n",
    "y_test= clf.predict(Test_Data)\n",
    "count=0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==Test_Data_Label[i]):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_test.shape[0])\n",
    "print(\"Test accuracy:\"),\n",
    "print(float(count*100)/y_test.shape[0])\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            tp=tp+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            fp=fp+1\n",
    "    if (y_test[i]==-1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            fn=fn+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            tn=tn+1\n",
    "#print(tp,fp,tn,fn)     \n",
    "precision = float(tp)/float(tp+fp)\n",
    "recall = float(tp)/float(tp+fn)\n",
    "F1_score = (2* precision* recall)/(precision+recall)\n",
    "print(\"Precision:\"),\n",
    "print(precision)\n",
    "print(\"Recall:\"),\n",
    "print(recall)\n",
    "print(\"F1 Score:\"),\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 77.8223783241\n",
      "Test accuracy: 40.9673715434\n",
      "Precision: 0.0312175648703\n",
      "Recall: 0.784615384615\n",
      "F1 Score: 0.0600460711543\n"
     ]
    }
   ],
   "source": [
    "# Fold 3 Cross validation\n",
    "Train_Data = np.concatenate((Train_part1,Train_part2,Train_part4,Train_part5),axis=0)\n",
    "Test_Data = np.concatenate((Train_part3,X_other_users),axis=0)\n",
    "Test_Data_Label = np.concatenate((np.ones(Train_part3.shape[0],dtype=int),Y_other_users),axis=0)\n",
    "\n",
    "clf = svm.OneClassSVM(kernel='rbf', gamma=0.3, nu=0.22)\n",
    "clf.fit(Train_Data)\n",
    "\n",
    "\n",
    "# Accuracy on Training Data\n",
    "y_train= clf.predict(Train_Data)\n",
    "count=0\n",
    "for i in range(y_train.shape[0]):\n",
    "    if (y_train[i]==1):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_train.shape[0])\n",
    "print(\"Training accuracy:\"),\n",
    "print(float(count*100)/y_train.shape[0])\n",
    "\n",
    "\n",
    "# Accuracy on Test Data\n",
    "y_test= clf.predict(Test_Data)\n",
    "count=0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==Test_Data_Label[i]):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_test.shape[0])\n",
    "print(\"Test accuracy:\"),\n",
    "print(float(count*100)/y_test.shape[0])\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            tp=tp+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            fp=fp+1\n",
    "    if (y_test[i]==-1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            fn=fn+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            tn=tn+1\n",
    "#print(tp,fp,tn,fn)     \n",
    "precision = float(tp)/float(tp+fp)\n",
    "recall = float(tp)/float(tp+fn)\n",
    "F1_score = (2* precision* recall)/(precision+recall)\n",
    "print(\"Precision:\"),\n",
    "print(precision)\n",
    "print(\"Recall:\"),\n",
    "print(recall)\n",
    "print(\"F1 Score:\"),\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 78.273958856\n",
      "Test accuracy: 42.7279686154\n",
      "Precision: 0.031311468829\n",
      "Recall: 0.78273958856\n",
      "F1 Score: 0.0602142236804\n"
     ]
    }
   ],
   "source": [
    "# Fold 4 Cross validation\n",
    "Train_Data = np.concatenate((Train_part1,Train_part3,Train_part4,Train_part5),axis=0)\n",
    "Test_Data = np.concatenate((Train_part2,X_other_users),axis=0)\n",
    "Test_Data_Label = np.concatenate((np.ones(Train_part2.shape[0],dtype=int),Y_other_users),axis=0)\n",
    "\n",
    "\n",
    "\n",
    "clf = svm.OneClassSVM(kernel='rbf', gamma=0.3, nu=0.22)\n",
    "clf.fit(Train_Data)\n",
    "\n",
    "\n",
    "# Accuracy on Training Data\n",
    "y_train= clf.predict(Train_Data)\n",
    "count=0\n",
    "for i in range(y_train.shape[0]):\n",
    "    if (y_train[i]==1):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_train.shape[0])\n",
    "print(\"Training accuracy:\"),\n",
    "print(float(count*100)/y_train.shape[0])\n",
    "\n",
    "\n",
    "# Accuracy on Test Data\n",
    "y_test= clf.predict(Test_Data)\n",
    "count=0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==Test_Data_Label[i]):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_test.shape[0])\n",
    "print(\"Test accuracy:\"),\n",
    "print(float(count*100)/y_test.shape[0])\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            tp=tp+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            fp=fp+1\n",
    "    if (y_test[i]==-1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            fn=fn+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            tn=tn+1\n",
    "#print(tp,fp,tn,fn)     \n",
    "precision = float(tp)/float(tp+fp)\n",
    "recall = float(tp)/float(tp+fn)\n",
    "F1_score = (2* precision* recall)/(precision+recall)\n",
    "print(\"Precision:\"),\n",
    "print(precision)\n",
    "print(\"Recall:\"),\n",
    "print(recall)\n",
    "print(\"F1 Score:\"),\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 78.4746613146\n",
      "Test accuracy: 42.632283992\n",
      "Precision: 0.0312525171164\n",
      "Recall: 0.778803693296\n",
      "F1 Score: 0.0600935476876\n"
     ]
    }
   ],
   "source": [
    "# Fold 5 Cross validation\n",
    "Train_Data = np.concatenate((Train_part2,Train_part3,Train_part4,Train_part5),axis=0)\n",
    "Test_Data = np.concatenate((Train_part1,X_other_users),axis=0)\n",
    "Test_Data_Label = np.concatenate((np.ones(Train_part1.shape[0],dtype=int),Y_other_users),axis=0)\n",
    "\n",
    "\n",
    "clf = svm.OneClassSVM(kernel='rbf', gamma=0.3, nu=0.22)\n",
    "clf.fit(Train_Data)\n",
    "\n",
    "\n",
    "# Accuracy on Training Data\n",
    "y_train= clf.predict(Train_Data)\n",
    "count=0\n",
    "for i in range(y_train.shape[0]):\n",
    "    if (y_train[i]==1):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_train.shape[0])\n",
    "print(\"Training accuracy:\"),\n",
    "print(float(count*100)/y_train.shape[0])\n",
    "\n",
    "\n",
    "# Accuracy on Test Data\n",
    "y_test= clf.predict(Test_Data)\n",
    "count=0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==Test_Data_Label[i]):\n",
    "        count=count+1\n",
    "    #print(count)\n",
    "    #print(y_test.shape[0])\n",
    "print(\"Test accuracy:\"),\n",
    "print(float(count*100)/y_test.shape[0])\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i]==1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            tp=tp+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            fp=fp+1\n",
    "    if (y_test[i]==-1):\n",
    "        if(Test_Data_Label[i]==1):\n",
    "            fn=fn+1\n",
    "        if(Test_Data_Label[i]==-1):\n",
    "            tn=tn+1\n",
    "#print(tp,fp,tn,fn)     \n",
    "precision = float(tp)/float(tp+fp)\n",
    "recall = float(tp)/float(tp+fn)\n",
    "F1_score = (2* precision* recall)/(precision+recall)\n",
    "    \n",
    "print(\"Precision:\"),\n",
    "print(precision)\n",
    "print(\"Recall:\"),\n",
    "print(recall)\n",
    "print(\"F1 Score:\"),\n",
    "print(F1_score)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
